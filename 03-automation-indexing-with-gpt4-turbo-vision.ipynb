{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“‹ Table of Contents\n",
    "\n",
    "This notebook guides you through the following sections:\n",
    "\n",
    "1. [**Optical Character Recognition (OCR) with Azure AI Document Intelligence**](#optical-character-recognition-ocr-with-azure-ai-document-intelligence): Overview of Azure's Document Analysis Client and its pre-trained models for document analysis.\n",
    "\n",
    "2. [**Understanding Data Extracted from the Layout Model**](#understanding-data-extracted-from-the-layout-model): Insights into the data extracted from the layout model.\n",
    "    - [**Custom Logic for Processing Extracted Information**](#custom-logic-for-processing-extracted-information): Discusses the need for custom logic to process the extracted information based on specific use cases and requirements.\n",
    "    - [**Leveraging LangChain Integration**](#leveraging-langchain-integration): Explanation of how Retrieval-Augmented Generation (RAG) works with a pretrained Large Language Model (LLM) and an external data retrieval system for dynamic interaction with documents and content generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory changed to C:\\Users\\pablosal\\Desktop\\gbbai-azure-ai-document-intelligence\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the target directory\n",
    "target_directory = r\"C:\\Users\\pablosal\\Desktop\\gbbai-azure-ai-document-intelligence\"  # change your directory here\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(target_directory):\n",
    "    # Change the current working directory\n",
    "    os.chdir(target_directory)\n",
    "    print(f\"Directory changed to {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"Directory {target_directory} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.azure_search_ai.indexer import AzureIndexerManager\n",
    "az_indexer_client = AzureIndexerManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchAlgorithmKind,\n",
    "    HnswParameters,\n",
    "    SearchField,\n",
    "    VectorSearch,\n",
    "    VectorSearchAlgorithmMetric,\n",
    "    ExhaustiveKnnAlgorithmConfiguration,\n",
    "    ExhaustiveKnnParameters,\n",
    "    VectorSearchProfile,\n",
    "    SemanticConfiguration,\n",
    "    SemanticField,\n",
    "    SemanticSearch,\n",
    "    SemanticPrioritizedFields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define field types for index \n",
    "images_index_fields = [\n",
    "    SimpleField(\n",
    "        name=\"id\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        key=True,\n",
    "        sortable=True,\n",
    "        filterable=True,\n",
    "        facetable=True,\n",
    "    ),\n",
    "    SimpleField(name=\"url\", type=SearchFieldDataType.String),\n",
    "    SimpleField(name=\"categoryEnriched\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"title\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"summary\", type=SearchFieldDataType.String),\n",
    "    SearchField(\n",
    "        name=\"summaryVector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        searchable=True,\n",
    "        vector_search_dimensions=1536,\n",
    "        vector_search_profile_name=\"myHnswProfile\",\n",
    "    )\n",
    "]\n",
    "\n",
    "# Configure the vector search configuration\n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(\n",
    "            name=\"myHnsw\",\n",
    "            kind=VectorSearchAlgorithmKind.HNSW,\n",
    "            parameters=HnswParameters(\n",
    "                m=5,\n",
    "                ef_construction=300,\n",
    "                ef_search=400,\n",
    "                metric=VectorSearchAlgorithmMetric.COSINE,\n",
    "            ),\n",
    "        ),\n",
    "        ExhaustiveKnnAlgorithmConfiguration(\n",
    "            name=\"myExhaustiveKnn\",\n",
    "            kind=VectorSearchAlgorithmKind.EXHAUSTIVE_KNN,\n",
    "            parameters=ExhaustiveKnnParameters(\n",
    "                metric=VectorSearchAlgorithmMetric.COSINE\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"myHnswProfile\",\n",
    "            algorithm_configuration_name=\"myHnsw\",\n",
    "        ),\n",
    "        VectorSearchProfile(\n",
    "            name=\"myExhaustiveKnnProfile\",\n",
    "            algorithm_configuration_name=\"myExhaustiveKnn\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "semantic_config_images = SemanticConfiguration(\n",
    "    name=\"images-index-semantic-config\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"title\"),\n",
    "        keywords_fields=[SemanticField(field_name=\"categoryEnriched\")],\n",
    "        content_fields=[SemanticField(field_name=\"summary\")],\n",
    "    ),\n",
    ")\n",
    "# Create the semantic settings with the configuration\n",
    "semantic_search = SemanticSearch(\n",
    "    configurations=[semantic_config_images]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 23:04:19,366 - micro - MainProcess - INFO     Index image-ocr-index created (core.py:create_index:132)\n"
     ]
    }
   ],
   "source": [
    "az_indexer_client.create_index(index_name=\"image-ocr-index\",\n",
    "                              fields=images_index_fields, \n",
    "                              vector_search=vector_search,\n",
    "                              semantic_search=semantic_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DataSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 23:04:20,769 - micro - MainProcess - INFO     Data source 'ocr-image-blob-datasource' created or updated (core.py:create_data_source_connection:164)\n"
     ]
    }
   ],
   "source": [
    "az_indexer_client.create_data_source_connection(name=\"ocr-image-blob-datasource\", \n",
    "                                                description='''Data source for OCR images extracted from PDFs \n",
    "                                                for multimodal search purposes''', \n",
    "                                                container_name=\"ocrimages\", \n",
    "                                                type=\"azureblob\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Skills "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "az_indexer_client.skills = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs= [\n",
    "        {\n",
    "          \"name\": \"summaryText\",\n",
    "          \"source\": \"/document/summary/*\"\n",
    "        }\n",
    "      ]\n",
    "\n",
    "outputs = [\n",
    "        {\n",
    "          \"name\": \"embedding\",\n",
    "          \"targetName\": \"summaryVector\"\n",
    "        }\n",
    "      ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az_indexer_client.skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "az_indexer_client.add_skill(odata_type=\"EmbeddingSkill\",\n",
    "                                name=\"image-ocr-embedding-skill\",\n",
    "                                description=\"Vectorize summaries extracted from images using ada\",\n",
    "                                context=\"/document/summary/*\",\n",
    "                                inputs=inputs,\n",
    "                                outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating skillsets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 23:07:41,999 - micro - MainProcess - INFO     Skillset: \n",
      "{\n",
      "    \"name\": \"image-ocr-skillset-4\",\n",
      "    \"description\": \"Skillset for OCR images extracted from PDFs\",\n",
      "    \"skills\": [\n",
      "        {\n",
      "            \"@odata.type\": \"#Microsoft.Skills.Text.AzureOpenAIEmbeddingSkill\",\n",
      "            \"name\": \"image-ocr-embedding-skill\",\n",
      "            \"description\": \"Vectorize summaries extracted from images using ada\",\n",
      "            \"context\": \"/document/summary/*\",\n",
      "            \"resourceUri\": \"https://ml-workspace-dev-canadaeast-001-aoai.openai.azure.com\",\n",
      "            \"apiKey\": \"d0fabc0b5f9c4b57a864761dd0eb146d\",\n",
      "            \"deploymentId\": \"foundational-canadaeast-ada\",\n",
      "            \"inputs\": [\n",
      "                {\n",
      "                    \"name\": \"summaryText\",\n",
      "                    \"source\": \"/document/summary/*\"\n",
      "                }\n",
      "            ],\n",
      "            \"outputs\": [\n",
      "                {\n",
      "                    \"name\": \"embedding\",\n",
      "                    \"targetName\": \"summaryVector\"\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "} (indexer.py:create_skillset:123)\n",
      "2024-01-21 23:07:42,571 - micro - MainProcess - ERROR    HTTP error occurred: 400 Client Error: Bad Request for url: https://azure-ai-search-dev-eastus-001.search.windows.net/skillsets?&api-version=2023-10-01-Preview (core.py:call_azure_search_api:105)\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pablosal\\Desktop\\gbbai-azure-ai-document-intelligence\\src\\azure_search_ai\\core.py\", line 103, in call_azure_search_api\n",
      "    response.raise_for_status()\n",
      "  File \"c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\document-intelligence\\lib\\site-packages\\requests\\models.py\", line 1021, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://azure-ai-search-dev-eastus-001.search.windows.net/skillsets?&api-version=2023-10-01-Preview\n"
     ]
    }
   ],
   "source": [
    "az_indexer_client.create_skillset(name=\"image-ocr-skillset-4\",\n",
    "                                  description=\"Skillset for OCR images extracted from PDFs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "document-intelligence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
