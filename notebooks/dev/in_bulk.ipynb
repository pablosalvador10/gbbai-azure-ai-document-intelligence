{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import concurrent.futures\n",
    "import os, time\n",
    "import tempfile\n",
    "import promptflow as pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install azure-ai-generative[evaluate]\n",
    "#!pip install azure-ai-generative\n",
    "#!pip install azure-ai-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C:\\Users\\pablosal\\Desktop\\gbbai-azure-ai-document-intelligence\\src\\evaluators\\flow.dag.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_FLOW = \"C:\\\\Users\\\\pablosal\\\\Desktop\\\\gbbai-azure-ai-document-intelligence\\\\src\\\\evaluators\\\\flow.dag.yaml\"\n",
    "chat_history = []\n",
    "question = \"What is the best way to manufacture a car?\"\n",
    "answer = \"audi\"\n",
    "context = \"because is better than bmw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-20 20:38:19 -0600   45416 execution.flow     INFO     Start executing nodes in thread pool mode.\n",
      "2024-01-20 20:38:19 -0600   45416 execution.flow     INFO     Start to run 8 nodes with concurrency level 16.\n",
      "2024-01-20 20:38:19 -0600   45416 execution.flow     INFO     Executing node coherence_score. node run id: 210100c1-f9e7-4b35-b78e-ecc099781195_coherence_score_0\n",
      "2024-01-20 20:38:19 -0600   45416 execution.flow     INFO     Executing node fluency_score. node run id: 210100c1-f9e7-4b35-b78e-ecc099781195_fluency_score_0\n",
      "2024-01-20 20:38:19 -0600   45416 execution.flow     INFO     Executing node groundedness_score. node run id: 210100c1-f9e7-4b35-b78e-ecc099781195_groundedness_score_0\n",
      "2024-01-20 20:38:19 -0600   45416 execution.flow     INFO     Executing node relevance_score. node run id: 210100c1-f9e7-4b35-b78e-ecc099781195_relevance_score_0\n",
      "2024-01-20 20:38:20 -0600   45416 execution.flow     INFO     Node fluency_score completes.\n",
      "2024-01-20 20:38:20 -0600   45416 execution.flow     INFO     Executing node fluency_concat_scores. node run id: 210100c1-f9e7-4b35-b78e-ecc099781195_fluency_concat_scores_0\n",
      "2024-01-20 20:38:20 -0600   45416 execution.flow     INFO     Node relevance_score completes.\n",
      "2024-01-20 20:38:20 -0600   45416 execution.flow     INFO     Node fluency_concat_scores completes.\n",
      "2024-01-20 20:38:20 -0600   45416 execution.flow     INFO     Executing node relevance_concat_scores. node run id: 210100c1-f9e7-4b35-b78e-ecc099781195_relevance_concat_scores_0\n",
      "2024-01-20 20:38:20 -0600   45416 execution.flow     INFO     Node relevance_concat_scores completes.\n",
      "2024-01-20 20:38:20 -0600   45416 execution.flow     INFO     Node coherence_score completes.\n",
      "2024-01-20 20:38:20 -0600   45416 execution.flow     INFO     Executing node coherence_concat_scores. node run id: 210100c1-f9e7-4b35-b78e-ecc099781195_coherence_concat_scores_0\n",
      "2024-01-20 20:38:20 -0600   45416 execution.flow     INFO     Node coherence_concat_scores completes.\n",
      "2024-01-20 20:38:20 -0600   45416 execution.flow     INFO     Node groundedness_score completes.\n",
      "2024-01-20 20:38:20 -0600   45416 execution.flow     INFO     Executing node groundedness_concat_scores. node run id: 210100c1-f9e7-4b35-b78e-ecc099781195_groundedness_concat_scores_0\n",
      "2024-01-20 20:38:20 -0600   45416 execution.flow     INFO     Node groundedness_concat_scores completes.\n",
      "2024-01-20 20:38:20 -0600   45416 execution.flow     INFO     Start to run 4 nodes with concurrency level 16.\n",
      "2024-01-20 20:38:20 -0600   45416 execution.flow     INFO     Executing node coherence_aggregate_variants_results. node run id: 3eed1ccc-bb8b-47c1-a767-ce6397441d4b_coherence_aggregate_variants_results_reduce\n",
      "2024-01-20 20:38:20 -0600   45416 execution.flow     INFO     Executing node fluency_aggregate_variants_results. node run id: 3eed1ccc-bb8b-47c1-a767-ce6397441d4b_fluency_aggregate_variants_results_reduce\n",
      "2024-01-20 20:38:20 -0600   45416 execution.flow     INFO     Executing node groundedness_aggregate_variants_results. node run id: 3eed1ccc-bb8b-47c1-a767-ce6397441d4b_groundedness_aggregate_variants_results_reduce\n",
      "2024-01-20 20:38:20 -0600   45416 execution.flow     INFO     Node coherence_aggregate_variants_results completes.\n",
      "2024-01-20 20:38:20 -0600   45416 execution.flow     INFO     Executing node relevance_aggregate_variants_results. node run id: 3eed1ccc-bb8b-47c1-a767-ce6397441d4b_relevance_aggregate_variants_results_reduce\n",
      "2024-01-20 20:38:20 -0600   45416 execution.flow     INFO     Node fluency_aggregate_variants_results completes.\n",
      "2024-01-20 20:38:20 -0600   45416 execution.flow     INFO     Node groundedness_aggregate_variants_results completes.\n",
      "2024-01-20 20:38:20 -0600   45416 execution.flow     INFO     Node relevance_aggregate_variants_results completes.\n",
      "result: {'gpt_coherence': 1.0, 'gpt_fluency': 1.0, 'gpt_groundedness': 3.0, 'gpt_relevance': 1.0}\n"
     ]
    }
   ],
   "source": [
    "cli = pf.PFClient()\n",
    "result = cli.test(\n",
    "    EVAL_FLOW,\n",
    "    inputs=dict(\n",
    "        chat_history=chat_history, question=question, answer=answer, context=context\n",
    "    ),\n",
    ")\n",
    "print(\"result:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Any\n",
    "\n",
    "\n",
    "def call_pf_client_and_test(\n",
    "    eval_flow: str, chat_history: List[str], question: str, answer: str, context: str\n",
    ") -> Any:\n",
    "    \"\"\"\n",
    "    Creates an instance of PFClient, calls the test method with provided arguments, and returns the result.\n",
    "\n",
    "    Parameters:\n",
    "    eval_flow (str): The path to the evaluation flow file.\n",
    "    chat_history (List[str]): The chat history to be passed to the test method.\n",
    "    question (str): The question to be passed to the test method.\n",
    "    answer (str): The answer to be passed to the test method.\n",
    "    context (str): The context to be passed to the test method.\n",
    "\n",
    "    Returns:\n",
    "    Any: The result returned from the test method of PFClient.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create an instance of PFClient\n",
    "    cli = pf.PFClient()\n",
    "\n",
    "    # Call the test method and return the result\n",
    "    return cli.test(\n",
    "        eval_flow,\n",
    "        inputs=dict(\n",
    "            chat_history=chat_history, question=question, answer=answer, context=context\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from typing import List\n",
    "\n",
    "# Set up logger\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def extract_conversation_data(file_path: str, eval_flow: str) -> None:\n",
    "    \"\"\"\n",
    "    Extracts and logs questions, user responses, and context from a newline-delimited JSON file.\n",
    "    Calls the call_pf_client_and_test function for each line and collects results in a summary table.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): The path to the newline-delimited JSON file.\n",
    "    eval_flow (str): The path to the evaluation flow file.\n",
    "\n",
    "    Returns:\n",
    "    None: This function does not return anything. It prints a summary of results.\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            for line in file:\n",
    "                try:\n",
    "                    data = json.loads(line.strip())\n",
    "                    chat_history = []\n",
    "                    question = \"\"\n",
    "                    answer = \"\"\n",
    "                    context = \"\"\n",
    "\n",
    "                    for item in data.get(\"messages\", []):\n",
    "                        role = item.get(\"role\", \"\")\n",
    "                        content = item.get(\"content\", \"\")\n",
    "                        if role == \"system\":\n",
    "                            question = content\n",
    "                        elif role == \"user\":\n",
    "                            answer = content\n",
    "                        elif role == \"context\":\n",
    "                            context = content\n",
    "\n",
    "                    if question and answer and context:\n",
    "                        result = call_pf_client_and_test(\n",
    "                            eval_flow, chat_history, question, answer, context\n",
    "                        )\n",
    "                        results.append((question, answer, context, result))\n",
    "\n",
    "                except json.JSONDecodeError as e:\n",
    "                    logger.error(\"JSONDecodeError while parsing line: %s\", e)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(\"An error occurred: %s\", e)\n",
    "        raise\n",
    "\n",
    "    # Print summary table\n",
    "    print(\"\\nSummary of Results:\")\n",
    "    print(\"Question | Answer | Context | Result\")\n",
    "    print(\"-\" * 50)\n",
    "    for q, a, c, r in results:\n",
    "        print(f\"{q} | {a} | {c} | {r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-28 19:43:16 -0600    9828 execution.flow     INFO     Start to run 8 nodes with concurrency level 16.\n",
      "2023-11-28 19:43:16 -0600    9828 execution.flow     INFO     Executing node coherence_score. node run id: 9cc148df-bdff-4dd9-a490-204a7deb7b72_coherence_score_0\n",
      "2023-11-28 19:43:16 -0600    9828 execution.flow     INFO     Executing node fluency_score. node run id: 9cc148df-bdff-4dd9-a490-204a7deb7b72_fluency_score_0\n",
      "2023-11-28 19:43:16 -0600    9828 execution.flow     INFO     Executing node groundedness_score. node run id: 9cc148df-bdff-4dd9-a490-204a7deb7b72_groundedness_score_0\n",
      "2023-11-28 19:43:16 -0600    9828 execution.flow     INFO     Executing node relevance_score. node run id: 9cc148df-bdff-4dd9-a490-204a7deb7b72_relevance_score_0\n",
      "2023-11-28 19:43:17 -0600    9828 execution          WARNING  [fluency_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 42 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:43:17 -0600    9828 execution          WARNING  [fluency_score in line 0 (index starts from 0)] stderr> RateLimitError #0, Retry-After=42, Back off 42.0 seconds for retry.\n",
      "2023-11-28 19:43:17 -0600    9828 execution          WARNING  [relevance_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 42 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:43:17 -0600    9828 execution          WARNING  [relevance_score in line 0 (index starts from 0)] stderr> RateLimitError #0, Retry-After=42, Back off 42.0 seconds for retry.\n",
      "2023-11-28 19:43:17 -0600    9828 execution          WARNING  [groundedness_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 52 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:43:17 -0600    9828 execution          WARNING  [groundedness_score in line 0 (index starts from 0)] stderr> RateLimitError #0, Retry-After=52, Back off 52.0 seconds for retry.\n",
      "2023-11-28 19:43:18 -0600    9828 execution          WARNING  [coherence_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 42 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:43:18 -0600    9828 execution          WARNING  [coherence_score in line 0 (index starts from 0)] stderr> RateLimitError #0, Retry-After=42, Back off 42.0 seconds for retry.\n",
      "2023-11-28 19:44:00 -0600    9828 execution          WARNING  [coherence_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:44:00 -0600    9828 execution          WARNING  [coherence_score in line 0 (index starts from 0)] stderr> RateLimitError #1, Retry-After=10, Back off 20.0 seconds for retry.\n",
      "2023-11-28 19:44:00 -0600    9828 execution.flow     INFO     Node fluency_score completes.\n",
      "2023-11-28 19:44:00 -0600    9828 execution.flow     INFO     Executing node fluency_concat_scores. node run id: 9cc148df-bdff-4dd9-a490-204a7deb7b72_fluency_concat_scores_0\n",
      "2023-11-28 19:44:00 -0600    9828 execution.flow     INFO     Node fluency_concat_scores completes.\n",
      "2023-11-28 19:44:00 -0600    9828 execution.flow     INFO     Node relevance_score completes.\n",
      "2023-11-28 19:44:00 -0600    9828 execution.flow     INFO     Executing node relevance_concat_scores. node run id: 9cc148df-bdff-4dd9-a490-204a7deb7b72_relevance_concat_scores_0\n",
      "2023-11-28 19:44:00 -0600    9828 execution.flow     INFO     Node relevance_concat_scores completes.\n",
      "2023-11-28 19:44:10 -0600    9828 execution.flow     INFO     Node groundedness_score completes.\n",
      "2023-11-28 19:44:10 -0600    9828 execution.flow     INFO     Executing node groundedness_concat_scores. node run id: 9cc148df-bdff-4dd9-a490-204a7deb7b72_groundedness_concat_scores_0\n",
      "2023-11-28 19:44:10 -0600    9828 execution.flow     INFO     Node groundedness_concat_scores completes.\n",
      "2023-11-28 19:44:16 -0600    9828 execution          WARNING  coherence_score in line 0 has been running for 60 seconds, stacktrace of thread 28096:\n",
      "  File \"c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\build-your-own-copilot\\lib\\site-packages\\promptflow\\tools\\common.py\", line 188, in wrapper\n",
      "    time.sleep(retry_after_seconds)\n",
      "\n",
      "2023-11-28 19:44:20 -0600    9828 execution.flow     INFO     Node coherence_score completes.\n",
      "2023-11-28 19:44:20 -0600    9828 execution.flow     INFO     Executing node coherence_concat_scores. node run id: 9cc148df-bdff-4dd9-a490-204a7deb7b72_coherence_concat_scores_0\n",
      "2023-11-28 19:44:20 -0600    9828 execution.flow     INFO     Node coherence_concat_scores completes.\n",
      "2023-11-28 19:44:20 -0600    9828 execution.flow     INFO     Start to run 4 nodes with concurrency level 16.\n",
      "2023-11-28 19:44:20 -0600    9828 execution.flow     INFO     Executing node coherence_aggregate_variants_results. node run id: 6fe51618-65b8-41b0-988a-6317a7e49aed_coherence_aggregate_variants_results_reduce\n",
      "2023-11-28 19:44:20 -0600    9828 execution.flow     INFO     Executing node fluency_aggregate_variants_results. node run id: 6fe51618-65b8-41b0-988a-6317a7e49aed_fluency_aggregate_variants_results_reduce\n",
      "2023-11-28 19:44:20 -0600    9828 execution.flow     INFO     Executing node groundedness_aggregate_variants_results. node run id: 6fe51618-65b8-41b0-988a-6317a7e49aed_groundedness_aggregate_variants_results_reduce\n",
      "2023-11-28 19:44:20 -0600    9828 execution.flow     INFO     Node coherence_aggregate_variants_results completes.\n",
      "2023-11-28 19:44:20 -0600    9828 execution.flow     INFO     Node fluency_aggregate_variants_results completes.\n",
      "2023-11-28 19:44:20 -0600    9828 execution.flow     INFO     Executing node relevance_aggregate_variants_results. node run id: 6fe51618-65b8-41b0-988a-6317a7e49aed_relevance_aggregate_variants_results_reduce\n",
      "2023-11-28 19:44:20 -0600    9828 execution.flow     INFO     Node groundedness_aggregate_variants_results completes.\n",
      "2023-11-28 19:44:20 -0600    9828 execution.flow     INFO     Node relevance_aggregate_variants_results completes.\n",
      "2023-11-28 19:44:20 -0600    9828 execution.flow     INFO     Start to run 8 nodes with concurrency level 16.\n",
      "2023-11-28 19:44:20 -0600    9828 execution.flow     INFO     Executing node coherence_score. node run id: 69906ddb-cfd0-4e25-9cb2-c7b46e7e4a85_coherence_score_0\n",
      "2023-11-28 19:44:20 -0600    9828 execution.flow     INFO     Executing node fluency_score. node run id: 69906ddb-cfd0-4e25-9cb2-c7b46e7e4a85_fluency_score_0\n",
      "2023-11-28 19:44:20 -0600    9828 execution.flow     INFO     Executing node groundedness_score. node run id: 69906ddb-cfd0-4e25-9cb2-c7b46e7e4a85_groundedness_score_0\n",
      "2023-11-28 19:44:20 -0600    9828 execution.flow     INFO     Executing node relevance_score. node run id: 69906ddb-cfd0-4e25-9cb2-c7b46e7e4a85_relevance_score_0\n",
      "2023-11-28 19:44:21 -0600    9828 execution          WARNING  [coherence_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 39 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:44:21 -0600    9828 execution          WARNING  [coherence_score in line 0 (index starts from 0)] stderr> RateLimitError #0, Retry-After=39, Back off 39.0 seconds for retry.\n",
      "2023-11-28 19:44:21 -0600    9828 execution          WARNING  [fluency_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 39 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:44:21 -0600    9828 execution          WARNING  [fluency_score in line 0 (index starts from 0)] stderr> RateLimitError #0, Retry-After=39, Back off 39.0 seconds for retry.\n",
      "2023-11-28 19:44:21 -0600    9828 execution          WARNING  [groundedness_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 39 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:44:21 -0600    9828 execution          WARNING  [groundedness_score in line 0 (index starts from 0)] stderr> RateLimitError #0, Retry-After=39, Back off 39.0 seconds for retry.\n",
      "2023-11-28 19:44:21 -0600    9828 execution          WARNING  [relevance_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 39 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:44:21 -0600    9828 execution          WARNING  [relevance_score in line 0 (index starts from 0)] stderr> RateLimitError #0, Retry-After=39, Back off 39.0 seconds for retry.\n",
      "2023-11-28 19:45:01 -0600    9828 execution.flow     INFO     Node coherence_score completes.\n",
      "2023-11-28 19:45:01 -0600    9828 execution.flow     INFO     Executing node coherence_concat_scores. node run id: 69906ddb-cfd0-4e25-9cb2-c7b46e7e4a85_coherence_concat_scores_0\n",
      "2023-11-28 19:45:01 -0600    9828 execution.flow     INFO     Node coherence_concat_scores completes.\n",
      "2023-11-28 19:45:01 -0600    9828 execution.flow     INFO     Node fluency_score completes.\n",
      "2023-11-28 19:45:01 -0600    9828 execution.flow     INFO     Executing node fluency_concat_scores. node run id: 69906ddb-cfd0-4e25-9cb2-c7b46e7e4a85_fluency_concat_scores_0\n",
      "2023-11-28 19:45:01 -0600    9828 execution.flow     INFO     Node fluency_concat_scores completes.\n",
      "2023-11-28 19:45:01 -0600    9828 execution.flow     INFO     Node groundedness_score completes.\n",
      "2023-11-28 19:45:01 -0600    9828 execution.flow     INFO     Node relevance_score completes.\n",
      "2023-11-28 19:45:01 -0600    9828 execution.flow     INFO     Executing node groundedness_concat_scores. node run id: 69906ddb-cfd0-4e25-9cb2-c7b46e7e4a85_groundedness_concat_scores_0\n",
      "2023-11-28 19:45:01 -0600    9828 execution.flow     INFO     Executing node relevance_concat_scores. node run id: 69906ddb-cfd0-4e25-9cb2-c7b46e7e4a85_relevance_concat_scores_0\n",
      "2023-11-28 19:45:01 -0600    9828 execution.flow     INFO     Node groundedness_concat_scores completes.\n",
      "2023-11-28 19:45:01 -0600    9828 execution.flow     INFO     Node relevance_concat_scores completes.\n",
      "2023-11-28 19:45:01 -0600    9828 execution.flow     INFO     Start to run 4 nodes with concurrency level 16.\n",
      "2023-11-28 19:45:01 -0600    9828 execution.flow     INFO     Executing node coherence_aggregate_variants_results. node run id: dfcac985-d53a-48cb-8648-e16fb54a626f_coherence_aggregate_variants_results_reduce\n",
      "2023-11-28 19:45:01 -0600    9828 execution.flow     INFO     Executing node fluency_aggregate_variants_results. node run id: dfcac985-d53a-48cb-8648-e16fb54a626f_fluency_aggregate_variants_results_reduce\n",
      "2023-11-28 19:45:01 -0600    9828 execution.flow     INFO     Node coherence_aggregate_variants_results completes.\n",
      "2023-11-28 19:45:01 -0600    9828 execution.flow     INFO     Executing node groundedness_aggregate_variants_results. node run id: dfcac985-d53a-48cb-8648-e16fb54a626f_groundedness_aggregate_variants_results_reduce\n",
      "2023-11-28 19:45:01 -0600    9828 execution.flow     INFO     Node fluency_aggregate_variants_results completes.\n",
      "2023-11-28 19:45:01 -0600    9828 execution.flow     INFO     Executing node relevance_aggregate_variants_results. node run id: dfcac985-d53a-48cb-8648-e16fb54a626f_relevance_aggregate_variants_results_reduce\n",
      "2023-11-28 19:45:01 -0600    9828 execution.flow     INFO     Node groundedness_aggregate_variants_results completes.\n",
      "2023-11-28 19:45:01 -0600    9828 execution.flow     INFO     Node relevance_aggregate_variants_results completes.\n",
      "2023-11-28 19:45:01 -0600    9828 execution.flow     INFO     Start to run 8 nodes with concurrency level 16.\n",
      "2023-11-28 19:45:01 -0600    9828 execution.flow     INFO     Executing node coherence_score. node run id: 7ccd1e76-6c38-4ee2-8790-f48d7b6fe863_coherence_score_0\n",
      "2023-11-28 19:45:01 -0600    9828 execution.flow     INFO     Executing node fluency_score. node run id: 7ccd1e76-6c38-4ee2-8790-f48d7b6fe863_fluency_score_0\n",
      "2023-11-28 19:45:01 -0600    9828 execution.flow     INFO     Executing node groundedness_score. node run id: 7ccd1e76-6c38-4ee2-8790-f48d7b6fe863_groundedness_score_0\n",
      "2023-11-28 19:45:01 -0600    9828 execution.flow     INFO     Executing node relevance_score. node run id: 7ccd1e76-6c38-4ee2-8790-f48d7b6fe863_relevance_score_0\n",
      "2023-11-28 19:45:02 -0600    9828 execution          WARNING  [groundedness_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 59 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:45:02 -0600    9828 execution          WARNING  [groundedness_score in line 0 (index starts from 0)] stderr> RateLimitError #0, Retry-After=59, Back off 59.0 seconds for retry.\n",
      "2023-11-28 19:45:02 -0600    9828 execution          WARNING  [coherence_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 59 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:45:02 -0600    9828 execution          WARNING  [coherence_score in line 0 (index starts from 0)] stderr> RateLimitError #0, Retry-After=59, Back off 59.0 seconds for retry.\n",
      "2023-11-28 19:45:02 -0600    9828 execution          WARNING  [relevance_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 59 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:45:02 -0600    9828 execution          WARNING  [relevance_score in line 0 (index starts from 0)] stderr> RateLimitError #0, Retry-After=59, Back off 59.0 seconds for retry.\n",
      "2023-11-28 19:45:02 -0600    9828 execution          WARNING  [fluency_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 59 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:45:02 -0600    9828 execution          WARNING  [fluency_score in line 0 (index starts from 0)] stderr> RateLimitError #0, Retry-After=59, Back off 59.0 seconds for retry.\n",
      "2023-11-28 19:46:01 -0600    9828 execution          WARNING  coherence_score in line 0 has been running for 60 seconds, stacktrace of thread 21028:\n",
      "  File \"c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\build-your-own-copilot\\lib\\site-packages\\promptflow\\tools\\common.py\", line 188, in wrapper\n",
      "    time.sleep(retry_after_seconds)\n",
      "\n",
      "2023-11-28 19:46:01 -0600    9828 execution          WARNING  groundedness_score in line 0 has been running for 60 seconds, stacktrace of thread 21076:\n",
      "  File \"c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\build-your-own-copilot\\lib\\site-packages\\promptflow\\tools\\common.py\", line 188, in wrapper\n",
      "    time.sleep(retry_after_seconds)\n",
      "\n",
      "2023-11-28 19:46:01 -0600    9828 execution          WARNING  fluency_score in line 0 has been running for 60 seconds, stacktrace of thread 26012:\n",
      "  File \"c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\build-your-own-copilot\\lib\\site-packages\\promptflow\\tools\\common.py\", line 188, in wrapper\n",
      "    time.sleep(retry_after_seconds)\n",
      "\n",
      "2023-11-28 19:46:01 -0600    9828 execution          WARNING  relevance_score in line 0 has been running for 60 seconds, stacktrace of thread 15888:\n",
      "  File \"c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\build-your-own-copilot\\lib\\site-packages\\promptflow\\tools\\common.py\", line 188, in wrapper\n",
      "    time.sleep(retry_after_seconds)\n",
      "\n",
      "2023-11-28 19:46:02 -0600    9828 execution.flow     INFO     Node coherence_score completes.\n",
      "2023-11-28 19:46:02 -0600    9828 execution.flow     INFO     Executing node coherence_concat_scores. node run id: 7ccd1e76-6c38-4ee2-8790-f48d7b6fe863_coherence_concat_scores_0\n",
      "2023-11-28 19:46:02 -0600    9828 execution.flow     INFO     Node groundedness_score completes.\n",
      "2023-11-28 19:46:02 -0600    9828 execution.flow     INFO     Node relevance_score completes.\n",
      "2023-11-28 19:46:02 -0600    9828 execution.flow     INFO     Node coherence_concat_scores completes.\n",
      "2023-11-28 19:46:02 -0600    9828 execution.flow     INFO     Executing node groundedness_concat_scores. node run id: 7ccd1e76-6c38-4ee2-8790-f48d7b6fe863_groundedness_concat_scores_0\n",
      "2023-11-28 19:46:02 -0600    9828 execution.flow     INFO     Executing node relevance_concat_scores. node run id: 7ccd1e76-6c38-4ee2-8790-f48d7b6fe863_relevance_concat_scores_0\n",
      "2023-11-28 19:46:02 -0600    9828 execution.flow     INFO     Node relevance_concat_scores completes.\n",
      "2023-11-28 19:46:02 -0600    9828 execution.flow     INFO     Node groundedness_concat_scores completes.\n",
      "2023-11-28 19:46:02 -0600    9828 execution.flow     INFO     Node fluency_score completes.\n",
      "2023-11-28 19:46:02 -0600    9828 execution.flow     INFO     Executing node fluency_concat_scores. node run id: 7ccd1e76-6c38-4ee2-8790-f48d7b6fe863_fluency_concat_scores_0\n",
      "2023-11-28 19:46:02 -0600    9828 execution.flow     INFO     Node fluency_concat_scores completes.\n",
      "2023-11-28 19:46:02 -0600    9828 execution.flow     INFO     Start to run 4 nodes with concurrency level 16.\n",
      "2023-11-28 19:46:02 -0600    9828 execution.flow     INFO     Executing node coherence_aggregate_variants_results. node run id: 8ce8b7e2-509f-4198-9318-106a780764df_coherence_aggregate_variants_results_reduce\n",
      "2023-11-28 19:46:02 -0600    9828 execution.flow     INFO     Executing node fluency_aggregate_variants_results. node run id: 8ce8b7e2-509f-4198-9318-106a780764df_fluency_aggregate_variants_results_reduce\n",
      "2023-11-28 19:46:02 -0600    9828 execution.flow     INFO     Executing node groundedness_aggregate_variants_results. node run id: 8ce8b7e2-509f-4198-9318-106a780764df_groundedness_aggregate_variants_results_reduce\n",
      "2023-11-28 19:46:02 -0600    9828 execution.flow     INFO     Node coherence_aggregate_variants_results completes.\n",
      "2023-11-28 19:46:02 -0600    9828 execution.flow     INFO     Executing node relevance_aggregate_variants_results. node run id: 8ce8b7e2-509f-4198-9318-106a780764df_relevance_aggregate_variants_results_reduce\n",
      "2023-11-28 19:46:02 -0600    9828 execution.flow     INFO     Node fluency_aggregate_variants_results completes.\n",
      "2023-11-28 19:46:02 -0600    9828 execution.flow     INFO     Node groundedness_aggregate_variants_results completes.\n",
      "2023-11-28 19:46:02 -0600    9828 execution.flow     INFO     Node relevance_aggregate_variants_results completes.\n",
      "2023-11-28 19:46:02 -0600    9828 execution.flow     INFO     Start to run 8 nodes with concurrency level 16.\n",
      "2023-11-28 19:46:02 -0600    9828 execution.flow     INFO     Executing node coherence_score. node run id: 1bfab39a-b094-430d-8c8b-fe20aeb28829_coherence_score_0\n",
      "2023-11-28 19:46:02 -0600    9828 execution.flow     INFO     Executing node fluency_score. node run id: 1bfab39a-b094-430d-8c8b-fe20aeb28829_fluency_score_0\n",
      "2023-11-28 19:46:02 -0600    9828 execution.flow     INFO     Executing node groundedness_score. node run id: 1bfab39a-b094-430d-8c8b-fe20aeb28829_groundedness_score_0\n",
      "2023-11-28 19:46:02 -0600    9828 execution.flow     INFO     Executing node relevance_score. node run id: 1bfab39a-b094-430d-8c8b-fe20aeb28829_relevance_score_0\n",
      "2023-11-28 19:46:03 -0600    9828 execution          WARNING  [groundedness_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 58 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:46:03 -0600    9828 execution          WARNING  [groundedness_score in line 0 (index starts from 0)] stderr> RateLimitError #0, Retry-After=58, Back off 58.0 seconds for retry.\n",
      "2023-11-28 19:46:03 -0600    9828 execution          WARNING  [relevance_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 58 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:46:03 -0600    9828 execution          WARNING  [relevance_score in line 0 (index starts from 0)] stderr> RateLimitError #0, Retry-After=58, Back off 58.0 seconds for retry.\n",
      "2023-11-28 19:46:04 -0600    9828 execution.flow     INFO     Node coherence_score completes.\n",
      "2023-11-28 19:46:04 -0600    9828 execution.flow     INFO     Executing node coherence_concat_scores. node run id: 1bfab39a-b094-430d-8c8b-fe20aeb28829_coherence_concat_scores_0\n",
      "2023-11-28 19:46:04 -0600    9828 execution.flow     INFO     Node coherence_concat_scores completes.\n",
      "2023-11-28 19:46:04 -0600    9828 execution.flow     INFO     Node fluency_score completes.\n",
      "2023-11-28 19:46:04 -0600    9828 execution.flow     INFO     Executing node fluency_concat_scores. node run id: 1bfab39a-b094-430d-8c8b-fe20aeb28829_fluency_concat_scores_0\n",
      "2023-11-28 19:46:04 -0600    9828 execution.flow     INFO     Node fluency_concat_scores completes.\n",
      "2023-11-28 19:47:02 -0600    9828 execution.flow     INFO     Node relevance_score completes.\n",
      "2023-11-28 19:47:02 -0600    9828 execution.flow     INFO     Executing node relevance_concat_scores. node run id: 1bfab39a-b094-430d-8c8b-fe20aeb28829_relevance_concat_scores_0\n",
      "2023-11-28 19:47:02 -0600    9828 execution.flow     INFO     Node relevance_concat_scores completes.\n",
      "2023-11-28 19:47:02 -0600    9828 execution.flow     INFO     Node groundedness_score completes.\n",
      "2023-11-28 19:47:02 -0600    9828 execution.flow     INFO     Executing node groundedness_concat_scores. node run id: 1bfab39a-b094-430d-8c8b-fe20aeb28829_groundedness_concat_scores_0\n",
      "2023-11-28 19:47:02 -0600    9828 execution.flow     INFO     Node groundedness_concat_scores completes.\n",
      "2023-11-28 19:47:02 -0600    9828 execution.flow     INFO     Start to run 4 nodes with concurrency level 16.\n",
      "2023-11-28 19:47:02 -0600    9828 execution.flow     INFO     Executing node coherence_aggregate_variants_results. node run id: e51a9c70-0c35-4475-b219-c4056072e5ba_coherence_aggregate_variants_results_reduce\n",
      "2023-11-28 19:47:02 -0600    9828 execution.flow     INFO     Executing node fluency_aggregate_variants_results. node run id: e51a9c70-0c35-4475-b219-c4056072e5ba_fluency_aggregate_variants_results_reduce\n",
      "2023-11-28 19:47:02 -0600    9828 execution.flow     INFO     Executing node groundedness_aggregate_variants_results. node run id: e51a9c70-0c35-4475-b219-c4056072e5ba_groundedness_aggregate_variants_results_reduce\n",
      "2023-11-28 19:47:02 -0600    9828 execution.flow     INFO     Executing node relevance_aggregate_variants_results. node run id: e51a9c70-0c35-4475-b219-c4056072e5ba_relevance_aggregate_variants_results_reduce\n",
      "2023-11-28 19:47:02 -0600    9828 execution.flow     INFO     Node coherence_aggregate_variants_results completes.\n",
      "2023-11-28 19:47:02 -0600    9828 execution.flow     INFO     Node fluency_aggregate_variants_results completes.\n",
      "2023-11-28 19:47:02 -0600    9828 execution.flow     INFO     Node groundedness_aggregate_variants_results completes.\n",
      "2023-11-28 19:47:02 -0600    9828 execution.flow     INFO     Node relevance_aggregate_variants_results completes.\n",
      "2023-11-28 19:47:02 -0600    9828 execution.flow     INFO     Start to run 8 nodes with concurrency level 16.\n",
      "2023-11-28 19:47:02 -0600    9828 execution.flow     INFO     Executing node coherence_score. node run id: 5013bdc0-9649-4937-9b97-e507f11ff5de_coherence_score_0\n",
      "2023-11-28 19:47:02 -0600    9828 execution.flow     INFO     Executing node fluency_score. node run id: 5013bdc0-9649-4937-9b97-e507f11ff5de_fluency_score_0\n",
      "2023-11-28 19:47:02 -0600    9828 execution.flow     INFO     Executing node groundedness_score. node run id: 5013bdc0-9649-4937-9b97-e507f11ff5de_groundedness_score_0\n",
      "2023-11-28 19:47:02 -0600    9828 execution.flow     INFO     Executing node relevance_score. node run id: 5013bdc0-9649-4937-9b97-e507f11ff5de_relevance_score_0\n",
      "2023-11-28 19:47:03 -0600    9828 execution          WARNING  [coherence_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:47:03 -0600    9828 execution          WARNING  [coherence_score in line 0 (index starts from 0)] stderr> RateLimitError #0, Retry-After=1, Back off 1.0 seconds for retry.\n",
      "2023-11-28 19:47:03 -0600    9828 execution          WARNING  [groundedness_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:47:03 -0600    9828 execution          WARNING  [groundedness_score in line 0 (index starts from 0)] stderr> RateLimitError #0, Retry-After=1, Back off 1.0 seconds for retry.\n",
      "2023-11-28 19:47:03 -0600    9828 execution          WARNING  [fluency_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:47:03 -0600    9828 execution          WARNING  [fluency_score in line 0 (index starts from 0)] stderr> RateLimitError #0, Retry-After=1, Back off 1.0 seconds for retry.\n",
      "2023-11-28 19:47:03 -0600    9828 execution          WARNING  [relevance_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:47:03 -0600    9828 execution          WARNING  [relevance_score in line 0 (index starts from 0)] stderr> RateLimitError #0, Retry-After=1, Back off 1.0 seconds for retry.\n",
      "2023-11-28 19:47:04 -0600    9828 execution.flow     INFO     Node coherence_score completes.\n",
      "2023-11-28 19:47:04 -0600    9828 execution.flow     INFO     Executing node coherence_concat_scores. node run id: 5013bdc0-9649-4937-9b97-e507f11ff5de_coherence_concat_scores_0\n",
      "2023-11-28 19:47:04 -0600    9828 execution.flow     INFO     Node coherence_concat_scores completes.\n",
      "2023-11-28 19:47:05 -0600    9828 execution.flow     INFO     Node fluency_score completes.\n",
      "2023-11-28 19:47:05 -0600    9828 execution.flow     INFO     Executing node fluency_concat_scores. node run id: 5013bdc0-9649-4937-9b97-e507f11ff5de_fluency_concat_scores_0\n",
      "2023-11-28 19:47:05 -0600    9828 execution.flow     INFO     Node fluency_concat_scores completes.\n",
      "2023-11-28 19:47:05 -0600    9828 execution.flow     INFO     Node groundedness_score completes.\n",
      "2023-11-28 19:47:05 -0600    9828 execution.flow     INFO     Executing node groundedness_concat_scores. node run id: 5013bdc0-9649-4937-9b97-e507f11ff5de_groundedness_concat_scores_0\n",
      "2023-11-28 19:47:05 -0600    9828 execution.flow     INFO     Node relevance_score completes.\n",
      "2023-11-28 19:47:05 -0600    9828 execution.flow     INFO     Node groundedness_concat_scores completes.\n",
      "2023-11-28 19:47:05 -0600    9828 execution.flow     INFO     Executing node relevance_concat_scores. node run id: 5013bdc0-9649-4937-9b97-e507f11ff5de_relevance_concat_scores_0\n",
      "2023-11-28 19:47:05 -0600    9828 execution.flow     INFO     Node relevance_concat_scores completes.\n",
      "2023-11-28 19:47:05 -0600    9828 execution.flow     INFO     Start to run 4 nodes with concurrency level 16.\n",
      "2023-11-28 19:47:05 -0600    9828 execution.flow     INFO     Executing node coherence_aggregate_variants_results. node run id: ae01fdd0-7a8f-4ba4-93ae-20a1e9b0a576_coherence_aggregate_variants_results_reduce\n",
      "2023-11-28 19:47:05 -0600    9828 execution.flow     INFO     Executing node fluency_aggregate_variants_results. node run id: ae01fdd0-7a8f-4ba4-93ae-20a1e9b0a576_fluency_aggregate_variants_results_reduce\n",
      "2023-11-28 19:47:05 -0600    9828 execution.flow     INFO     Node coherence_aggregate_variants_results completes.\n",
      "2023-11-28 19:47:05 -0600    9828 execution.flow     INFO     Executing node groundedness_aggregate_variants_results. node run id: ae01fdd0-7a8f-4ba4-93ae-20a1e9b0a576_groundedness_aggregate_variants_results_reduce\n",
      "2023-11-28 19:47:05 -0600    9828 execution.flow     INFO     Executing node relevance_aggregate_variants_results. node run id: ae01fdd0-7a8f-4ba4-93ae-20a1e9b0a576_relevance_aggregate_variants_results_reduce\n",
      "2023-11-28 19:47:05 -0600    9828 execution.flow     INFO     Node fluency_aggregate_variants_results completes.\n",
      "2023-11-28 19:47:05 -0600    9828 execution.flow     INFO     Node groundedness_aggregate_variants_results completes.\n",
      "2023-11-28 19:47:05 -0600    9828 execution.flow     INFO     Node relevance_aggregate_variants_results completes.\n",
      "2023-11-28 19:47:05 -0600    9828 execution.flow     INFO     Start to run 8 nodes with concurrency level 16.\n",
      "2023-11-28 19:47:05 -0600    9828 execution.flow     INFO     Executing node coherence_score. node run id: aa530351-c1d3-42a3-a144-ceda8448d982_coherence_score_0\n",
      "2023-11-28 19:47:05 -0600    9828 execution.flow     INFO     Executing node fluency_score. node run id: aa530351-c1d3-42a3-a144-ceda8448d982_fluency_score_0\n",
      "2023-11-28 19:47:05 -0600    9828 execution.flow     INFO     Executing node groundedness_score. node run id: aa530351-c1d3-42a3-a144-ceda8448d982_groundedness_score_0\n",
      "2023-11-28 19:47:05 -0600    9828 execution.flow     INFO     Executing node relevance_score. node run id: aa530351-c1d3-42a3-a144-ceda8448d982_relevance_score_0\n",
      "2023-11-28 19:47:06 -0600    9828 execution          WARNING  [coherence_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:47:06 -0600    9828 execution          WARNING  [coherence_score in line 0 (index starts from 0)] stderr> RateLimitError #0, Retry-After=6, Back off 6.0 seconds for retry.\n",
      "2023-11-28 19:47:06 -0600    9828 execution          WARNING  [fluency_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:47:06 -0600    9828 execution          WARNING  [fluency_score in line 0 (index starts from 0)] stderr> RateLimitError #0, Retry-After=6, Back off 6.0 seconds for retry.\n",
      "2023-11-28 19:47:06 -0600    9828 execution          WARNING  [groundedness_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:47:06 -0600    9828 execution          WARNING  [groundedness_score in line 0 (index starts from 0)] stderr> RateLimitError #0, Retry-After=6, Back off 6.0 seconds for retry.\n",
      "2023-11-28 19:47:06 -0600    9828 execution          WARNING  [relevance_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:47:06 -0600    9828 execution          WARNING  [relevance_score in line 0 (index starts from 0)] stderr> RateLimitError #0, Retry-After=6, Back off 6.0 seconds for retry.\n",
      "2023-11-28 19:47:12 -0600    9828 execution          WARNING  [coherence_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 53 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:47:12 -0600    9828 execution          WARNING  [coherence_score in line 0 (index starts from 0)] stderr> RateLimitError #1, Retry-After=53, Back off 106.0 seconds for retry.\n",
      "2023-11-28 19:47:12 -0600    9828 execution          WARNING  [fluency_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 50 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:47:12 -0600    9828 execution          WARNING  [fluency_score in line 0 (index starts from 0)] stderr> RateLimitError #1, Retry-After=50, Back off 100.0 seconds for retry.\n",
      "2023-11-28 19:47:12 -0600    9828 execution          WARNING  [relevance_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 53 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:47:12 -0600    9828 execution          WARNING  [relevance_score in line 0 (index starts from 0)] stderr> RateLimitError #1, Retry-After=53, Back off 106.0 seconds for retry.\n",
      "2023-11-28 19:47:12 -0600    9828 execution          WARNING  [groundedness_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 53 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:47:12 -0600    9828 execution          WARNING  [groundedness_score in line 0 (index starts from 0)] stderr> RateLimitError #1, Retry-After=53, Back off 106.0 seconds for retry.\n",
      "2023-11-28 19:48:05 -0600    9828 execution          WARNING  coherence_score in line 0 has been running for 60 seconds, stacktrace of thread 10952:\n",
      "  File \"c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\build-your-own-copilot\\lib\\site-packages\\promptflow\\tools\\common.py\", line 188, in wrapper\n",
      "    time.sleep(retry_after_seconds)\n",
      "\n",
      "2023-11-28 19:48:05 -0600    9828 execution          WARNING  fluency_score in line 0 has been running for 60 seconds, stacktrace of thread 14292:\n",
      "  File \"c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\build-your-own-copilot\\lib\\site-packages\\promptflow\\tools\\common.py\", line 188, in wrapper\n",
      "    time.sleep(retry_after_seconds)\n",
      "\n",
      "2023-11-28 19:48:05 -0600    9828 execution          WARNING  groundedness_score in line 0 has been running for 60 seconds, stacktrace of thread 18528:\n",
      "  File \"c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\build-your-own-copilot\\lib\\site-packages\\promptflow\\tools\\common.py\", line 188, in wrapper\n",
      "    time.sleep(retry_after_seconds)\n",
      "\n",
      "2023-11-28 19:48:05 -0600    9828 execution          WARNING  relevance_score in line 0 has been running for 60 seconds, stacktrace of thread 31796:\n",
      "  File \"c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\build-your-own-copilot\\lib\\site-packages\\promptflow\\tools\\common.py\", line 188, in wrapper\n",
      "    time.sleep(retry_after_seconds)\n",
      "\n",
      "2023-11-28 19:48:53 -0600    9828 execution.flow     INFO     Node fluency_score completes.\n",
      "2023-11-28 19:48:53 -0600    9828 execution.flow     INFO     Executing node fluency_concat_scores. node run id: aa530351-c1d3-42a3-a144-ceda8448d982_fluency_concat_scores_0\n",
      "2023-11-28 19:48:53 -0600    9828 execution.flow     INFO     Node fluency_concat_scores completes.\n",
      "2023-11-28 19:48:59 -0600    9828 execution.flow     INFO     Node coherence_score completes.\n",
      "2023-11-28 19:48:59 -0600    9828 execution.flow     INFO     Node relevance_score completes.\n",
      "2023-11-28 19:48:59 -0600    9828 execution.flow     INFO     Node groundedness_score completes.\n",
      "2023-11-28 19:48:59 -0600    9828 execution.flow     INFO     Executing node coherence_concat_scores. node run id: aa530351-c1d3-42a3-a144-ceda8448d982_coherence_concat_scores_0\n",
      "2023-11-28 19:48:59 -0600    9828 execution.flow     INFO     Executing node relevance_concat_scores. node run id: aa530351-c1d3-42a3-a144-ceda8448d982_relevance_concat_scores_0\n",
      "2023-11-28 19:48:59 -0600    9828 execution.flow     INFO     Executing node groundedness_concat_scores. node run id: aa530351-c1d3-42a3-a144-ceda8448d982_groundedness_concat_scores_0\n",
      "2023-11-28 19:48:59 -0600    9828 execution.flow     INFO     Node coherence_concat_scores completes.\n",
      "2023-11-28 19:48:59 -0600    9828 execution.flow     INFO     Node relevance_concat_scores completes.\n",
      "2023-11-28 19:48:59 -0600    9828 execution.flow     INFO     Node groundedness_concat_scores completes.\n",
      "2023-11-28 19:48:59 -0600    9828 execution.flow     INFO     Start to run 4 nodes with concurrency level 16.\n",
      "2023-11-28 19:48:59 -0600    9828 execution.flow     INFO     Executing node coherence_aggregate_variants_results. node run id: 0577d8b8-e965-4b5a-89ec-7dcbca69c4d5_coherence_aggregate_variants_results_reduce\n",
      "2023-11-28 19:48:59 -0600    9828 execution.flow     INFO     Executing node fluency_aggregate_variants_results. node run id: 0577d8b8-e965-4b5a-89ec-7dcbca69c4d5_fluency_aggregate_variants_results_reduce\n",
      "2023-11-28 19:48:59 -0600    9828 execution.flow     INFO     Executing node groundedness_aggregate_variants_results. node run id: 0577d8b8-e965-4b5a-89ec-7dcbca69c4d5_groundedness_aggregate_variants_results_reduce\n",
      "2023-11-28 19:48:59 -0600    9828 execution.flow     INFO     Executing node relevance_aggregate_variants_results. node run id: 0577d8b8-e965-4b5a-89ec-7dcbca69c4d5_relevance_aggregate_variants_results_reduce\n",
      "2023-11-28 19:48:59 -0600    9828 execution.flow     INFO     Node groundedness_aggregate_variants_results completes.\n",
      "2023-11-28 19:48:59 -0600    9828 execution.flow     INFO     Node coherence_aggregate_variants_results completes.\n",
      "2023-11-28 19:48:59 -0600    9828 execution.flow     INFO     Node fluency_aggregate_variants_results completes.\n",
      "2023-11-28 19:48:59 -0600    9828 execution.flow     INFO     Node relevance_aggregate_variants_results completes.\n",
      "2023-11-28 19:48:59 -0600    9828 execution.flow     INFO     Start to run 8 nodes with concurrency level 16.\n",
      "2023-11-28 19:48:59 -0600    9828 execution.flow     INFO     Executing node coherence_score. node run id: 64c36884-b43b-4ecf-9da5-a2520520e4a5_coherence_score_0\n",
      "2023-11-28 19:48:59 -0600    9828 execution.flow     INFO     Executing node fluency_score. node run id: 64c36884-b43b-4ecf-9da5-a2520520e4a5_fluency_score_0\n",
      "2023-11-28 19:48:59 -0600    9828 execution.flow     INFO     Executing node groundedness_score. node run id: 64c36884-b43b-4ecf-9da5-a2520520e4a5_groundedness_score_0\n",
      "2023-11-28 19:48:59 -0600    9828 execution.flow     INFO     Executing node relevance_score. node run id: 64c36884-b43b-4ecf-9da5-a2520520e4a5_relevance_score_0\n",
      "2023-11-28 19:49:00 -0600    9828 execution          WARNING  [groundedness_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 59 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:49:00 -0600    9828 execution          WARNING  [relevance_score in line 0 (index starts from 0)] stderr> Exception occurs: RateLimitError: Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2023-07-01-preview have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 59 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n",
      "2023-11-28 19:49:00 -0600    9828 execution          WARNING  [groundedness_score in line 0 (index starts from 0)] stderr> RateLimitError #0, Retry-After=59, Back off 59.0 seconds for retry.\n",
      "2023-11-28 19:49:00 -0600    9828 execution          WARNING  [relevance_score in line 0 (index starts from 0)] stderr> RateLimitError #0, Retry-After=59, Back off 59.0 seconds for retry.\n",
      "2023-11-28 19:49:00 -0600    9828 execution.flow     INFO     Node coherence_score completes.\n",
      "2023-11-28 19:49:00 -0600    9828 execution.flow     INFO     Executing node coherence_concat_scores. node run id: 64c36884-b43b-4ecf-9da5-a2520520e4a5_coherence_concat_scores_0\n",
      "2023-11-28 19:49:00 -0600    9828 execution.flow     INFO     Node coherence_concat_scores completes.\n",
      "2023-11-28 19:49:00 -0600    9828 execution.flow     INFO     Node fluency_score completes.\n",
      "2023-11-28 19:49:00 -0600    9828 execution.flow     INFO     Executing node fluency_concat_scores. node run id: 64c36884-b43b-4ecf-9da5-a2520520e4a5_fluency_concat_scores_0\n",
      "2023-11-28 19:49:00 -0600    9828 execution.flow     INFO     Node fluency_concat_scores completes.\n",
      "2023-11-28 19:49:59 -0600    9828 execution          WARNING  groundedness_score in line 0 has been running for 60 seconds, stacktrace of thread 30268:\n",
      "  File \"c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\build-your-own-copilot\\lib\\site-packages\\promptflow\\tools\\common.py\", line 188, in wrapper\n",
      "    time.sleep(retry_after_seconds)\n",
      "\n",
      "2023-11-28 19:49:59 -0600    9828 execution          WARNING  relevance_score in line 0 has been running for 60 seconds, stacktrace of thread 29668:\n",
      "  File \"c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\build-your-own-copilot\\lib\\site-packages\\promptflow\\tools\\common.py\", line 188, in wrapper\n",
      "    time.sleep(retry_after_seconds)\n",
      "\n",
      "2023-11-28 19:49:59 -0600    9828 execution.flow     INFO     Node relevance_score completes.\n",
      "2023-11-28 19:50:00 -0600    9828 execution.flow     INFO     Executing node relevance_concat_scores. node run id: 64c36884-b43b-4ecf-9da5-a2520520e4a5_relevance_concat_scores_0\n",
      "2023-11-28 19:50:00 -0600    9828 execution.flow     INFO     Node relevance_concat_scores completes.\n",
      "2023-11-28 19:50:00 -0600    9828 execution.flow     INFO     Node groundedness_score completes.\n",
      "2023-11-28 19:50:00 -0600    9828 execution.flow     INFO     Executing node groundedness_concat_scores. node run id: 64c36884-b43b-4ecf-9da5-a2520520e4a5_groundedness_concat_scores_0\n",
      "2023-11-28 19:50:00 -0600    9828 execution.flow     INFO     Node groundedness_concat_scores completes.\n",
      "2023-11-28 19:50:00 -0600    9828 execution.flow     INFO     Start to run 4 nodes with concurrency level 16.\n",
      "2023-11-28 19:50:00 -0600    9828 execution.flow     INFO     Executing node coherence_aggregate_variants_results. node run id: 8916bfb7-f315-4603-9846-817218942caf_coherence_aggregate_variants_results_reduce\n",
      "2023-11-28 19:50:00 -0600    9828 execution.flow     INFO     Executing node fluency_aggregate_variants_results. node run id: 8916bfb7-f315-4603-9846-817218942caf_fluency_aggregate_variants_results_reduce\n",
      "2023-11-28 19:50:00 -0600    9828 execution.flow     INFO     Executing node groundedness_aggregate_variants_results. node run id: 8916bfb7-f315-4603-9846-817218942caf_groundedness_aggregate_variants_results_reduce\n",
      "2023-11-28 19:50:00 -0600    9828 execution.flow     INFO     Node coherence_aggregate_variants_results completes.\n",
      "2023-11-28 19:50:00 -0600    9828 execution.flow     INFO     Executing node relevance_aggregate_variants_results. node run id: 8916bfb7-f315-4603-9846-817218942caf_relevance_aggregate_variants_results_reduce\n",
      "2023-11-28 19:50:00 -0600    9828 execution.flow     INFO     Node fluency_aggregate_variants_results completes.\n",
      "2023-11-28 19:50:00 -0600    9828 execution.flow     INFO     Node groundedness_aggregate_variants_results completes.\n",
      "2023-11-28 19:50:00 -0600    9828 execution.flow     INFO     Node relevance_aggregate_variants_results completes.\n",
      "\n",
      "Summary of Results:\n",
      "Question | Answer | Context | Result\n",
      "--------------------------------------------------\n",
      "Question: How do I initiate the system startup procedure for the UltraFLEX HD PDU? | To initiate the system startup procedure, first ensure that all necessary connections are securely in place. Power on the system and wait for the initialization sequence to complete. Verify that all system indicators are showing normal operation status. If there are any error messages, refer to the troubleshooting section of the manual for guidance. | Refer to Chapter 3 of the UltraFLEX HD PDU User Manual for detailed startup procedures and initial setup instructions. | {'gpt_coherence': 5.0, 'gpt_fluency': 5.0, 'gpt_groundedness': 3.0, 'gpt_relevance': 5.0}\n",
      "Question: What are the key components of the UltraFLEX HD PDU? | The key components of the UltraFLEX HD PDU include the main power unit, control modules, interface connectors, and diagnostic tools. Each component plays a vital role in ensuring the proper functioning of the system. The main power unit supplies the required power, while the control modules manage the power distribution and system operations. | See Section 2.1 of the manual for a detailed overview of the system components and their functions. | {'gpt_coherence': 5.0, 'gpt_fluency': 5.0, 'gpt_groundedness': 1.0, 'gpt_relevance': 5.0}\n",
      "Question: What are the system ratings for the UltraFLEX HD PDU? | The system ratings for the UltraFLEX HD PDU include a voltage rating of up to 240V, a current rating of up to 20A, and a frequency range of 50-60Hz. These ratings are critical for ensuring that the system operates within safe and efficient parameters. | Refer to Chapter 5 for detailed specifications and system ratings. | {'gpt_coherence': 5.0, 'gpt_fluency': 5.0, 'gpt_groundedness': 1.0, 'gpt_relevance': 5.0}\n",
      "Question: How can I troubleshoot common issues with the UltraFLEX HD PDU? | To troubleshoot common issues, first check the error codes displayed on the system. Refer to the manual's troubleshooting section for explanations of these codes. Ensure all connections are secure and that the power supply is functioning correctly. If the problem persists, contact technical support for further assistance. | Chapter 7 provides a comprehensive guide on troubleshooting, including error code interpretations and solutions. | {'gpt_coherence': 5.0, 'gpt_fluency': 5.0, 'gpt_groundedness': 5.0, 'gpt_relevance': 5.0}\n",
      "Question: What safety precautions should I take when working with the UltraFLEX HD PDU? | Always follow standard electrical safety procedures. Ensure the system is powered off before making any physical connections or disconnections. Use proper grounding techniques and wear appropriate protective gear. Do not operate the system in wet or humid conditions to avoid electrical hazards. | Safety guidelines and precautions are detailed in Section 1.4 of the manual. | {'gpt_coherence': 5.0, 'gpt_fluency': 5.0, 'gpt_groundedness': 1.0, 'gpt_relevance': 5.0}\n",
      "Question: Can the UltraFLEX HD PDU be integrated with other systems? | Yes, the UltraFLEX HD PDU is designed for integration with various systems. It features multiple interface connectors that facilitate easy connection with different types of equipment. Refer to the manual for specific instructions on system integration. | For integration guidelines, see Chapter 4, which covers system integration and interface options. | {'gpt_coherence': 4.0, 'gpt_fluency': 5.0, 'gpt_groundedness': 5.0, 'gpt_relevance': 5.0}\n",
      "Question: What maintenance procedures are recommended for the UltraFLEX HD PDU? | Regular maintenance should include checking all connections for security and wear, verifying the condition of all cables and connectors, and ensuring that the system is clean and free from dust. Periodically test the system's functionality to ensure it operates as expected. | Maintenance procedures and schedules are outlined in Chapter 8 of the manual. | {'gpt_coherence': 5.0, 'gpt_fluency': 4.0, 'gpt_groundedness': 3.0, 'gpt_relevance': 3.0}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "extract_conversation_data(\n",
    "    file_path=\"C:\\\\Users\\\\pablosal\\\\Desktop\\\\azure-ai-gbb-solutions\\\\workshop\\\\solution\\\\build_your_own_copilot_aoai\\\\rag_pattern\\\\manufacturing_bot\\\\evaluation\\\\bulk\\\\validation.jsonl\",\n",
    "    eval_flow=EVAL_FLOW,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "build-your-own-copilot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
